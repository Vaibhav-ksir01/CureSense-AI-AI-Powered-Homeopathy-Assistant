{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI4E0xRsPnmx"
      },
      "source": [
        "# QA Model using Knowledge Graph and RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5gtnvsENmFf"
      },
      "source": [
        "Import all Neccessry Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1E_hECKhXrpi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from langchain_neo4j import Neo4jGraph\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from yfiles_jupyter_graphs import GraphWidget\n",
        "from neo4j import GraphDatabase\n",
        "from typing import Tuple, List\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain.chains.openai_functions import create_structured_output_runnable\n",
        "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda, RunnableBranch, RunnableParallel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkDCMDZwNx56"
      },
      "source": [
        "\n",
        "Set Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VYYWzceC48-Y"
      },
      "outputs": [],
      "source": [
        "# Load environment variables\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
        "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
        "NEO4J_URI = os.getenv('NEO4J_URI')\n",
        "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpH8gsUKOEHZ"
      },
      "source": [
        "Connect to the Neo4j Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "79oWgxkSIBR5"
      },
      "outputs": [],
      "source": [
        "# Establish connection to Neo4j\n",
        "graph = Neo4jGraph(url = NEO4J_URI, username = NEO4J_USERNAME, password = NEO4J_PASSWORD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYtZ9z6Pi7nu"
      },
      "source": [
        "**Store all PDFs in a Single Folder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HplF0sDwguaI"
      },
      "outputs": [],
      "source": [
        "def load_pdfs_from_folder(folder_path: str) -> dict:\n",
        "  \"\"\"Load all PDFs from a given folder and its subfolders, and store them in a dictionary.\n",
        "\n",
        "  Args:\n",
        "    folder_path: The path to the folder containing subfolders with PDF files.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary with the subfolder names as keys and the content of all PDFs in each subfolder as values.\n",
        "  \"\"\"\n",
        "  folder_dict = {}\n",
        "  j=1\n",
        "  for subfolder in os.listdir(folder_path):\n",
        "    subfolder_path = os.path.join(folder_path, subfolder)\n",
        "    if os.path.isdir(subfolder_path):\n",
        "      pdf_files = glob.glob(os.path.join(subfolder_path, \"*.pdf\"))\n",
        "      documents = []\n",
        "      print(j, \" \", subfolder)\n",
        "      i = 1\n",
        "      j+=1\n",
        "      for pdf_file in pdf_files:\n",
        "        loader = PyPDFLoader(pdf_file)\n",
        "        print(\"  \",i, \".  \", pdf_file)\n",
        "        documents.extend(loader.load())\n",
        "        i += 1\n",
        "      folder_dict[subfolder] = documents\n",
        "  return folder_dict\n",
        "\n",
        "folder_path = \"/home/vaibhavksir01/Downloads/project/Knowledge Graph/Class 6 textbooks\"\n",
        "raw_document = load_pdfs_from_folder(folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJwCC9OnPdF0"
      },
      "source": [
        "Split the text into small chunks and sorting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "te2pZ1KQLZdr"
      },
      "outputs": [],
      "source": [
        "text_splitter = TokenTextSplitter(chunk_size = 1024, chunk_overlap = 48)\n",
        "documents = {key: sorted(text_splitter.split_documents(value), key=lambda doc: doc.metadata['source']) for key, value in raw_document.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "for key, value in documents.items():\n",
        "    for doc in value:\n",
        "        unit = doc.metadata['source'].split(\". \") \n",
        "        unit = unit[len(unit)-1].replace('.pdf','')\n",
        "        doc.metadata['creator'] = key\n",
        "        doc.metadata['producer'] = key\n",
        "        if 'moddate' in doc.metadata:\n",
        "            doc.metadata.__delitem__('moddate')\n",
        "        if 'creationdate' in doc.metadata:\n",
        "            doc.metadata.__delitem__('creationdate')\n",
        "        doc.metadata['source'] = unit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1DqVC9INL9ai"
      },
      "outputs": [],
      "source": [
        "# Initialize Language Model\n",
        "llm = ChatOpenAI(api_key = OPENAI_API_KEY, model_name = \"gpt-3.5-turbo\", temperature = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urSjFvYL2pDc"
      },
      "source": [
        "Data to Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bleiZrhSNwJd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/vaibhavksir01/Downloads/project/QA chatbot/.venv/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "llm_transformer = LLMGraphTransformer(llm = llm) #Transformer that transform data to graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ypwZNPxnN_6M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start English\n",
            "complete\n",
            "\n",
            "start Science\n",
            "complete\n",
            "\n",
            "start Social Science\n",
            "complete\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Transforming the Data in a form that can be plotted as a Knowledge graph\n",
        "graph_document = {}\n",
        "for key, value in documents.items():\n",
        "    print(\"start\",key)\n",
        "    graph_document[key]=llm_transformer.convert_to_graph_documents(value)\n",
        "    print(\"complete\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KH98tnz4OSPM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English\n",
            "Science\n",
            "Social Science\n"
          ]
        }
      ],
      "source": [
        "#Plotting the Knowledge Graph\n",
        "for key, value in graph_document.items():\n",
        "    print(key)\n",
        "    graph.add_graph_documents(\n",
        "        value,\n",
        "        baseEntityLabel=True,\n",
        "        include_source=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doyU38qtQfBO"
      },
      "source": [
        "**Showing the Graph stored in the Neo4j Database**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eG3uGC7uOo9E"
      },
      "outputs": [],
      "source": [
        "default_cypher = \"MATCH p=(s)-[r]->(t) RETURN p\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LHLzLWb8O_df"
      },
      "outputs": [],
      "source": [
        "def showGraph(cypher: str = default_cypher):\n",
        "  driver = GraphDatabase.driver(\n",
        "      uri = NEO4J_URI,\n",
        "      auth = (NEO4J_USERNAME, NEO4J_PASSWORD)\n",
        "  )\n",
        "  session = driver.session()\n",
        "  widget = GraphWidget(graph = session.run(cypher).graph())\n",
        "  widget.node_label_mapping = 'id'\n",
        "  return widget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87cd8afe39b54bb8a739bc9874fefb8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "GraphWidget(layout=Layout(height='800px', width='100%'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "showGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pzGSByEQvrs"
      },
      "source": [
        "Creating Vectors indexes of the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZbTDDMt2ZTtt"
      },
      "outputs": [],
      "source": [
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    OpenAIEmbeddings(api_key = OPENAI_API_KEY),\n",
        "    search_type = \"hybrid\",\n",
        "    node_label = \"Document\",\n",
        "    text_node_properties = [\"text\"],\n",
        "    embedding_node_property = \"embedding\",\n",
        "    url = NEO4J_URI,\n",
        "    username = NEO4J_USERNAME,\n",
        "    password = NEO4J_PASSWORD\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gvGuxeWBaMyA"
      },
      "outputs": [],
      "source": [
        "class Entities(BaseModel):\n",
        "  \"\"\"Identifying information about entities\"\"\"\n",
        "  marks: dict = Field(\n",
        "    ...,\n",
        "    description=\"\"\"Dictionary containing the number of questions for each mark from 1 to 10.\n",
        "    Example- input generate 3questions of 1,2,5 marks respectively\n",
        "    output- {'1': 1, '2': 1, '3': 0, '4': 0, '5': 1, '6': 0, '7': 0, '8': 0, '9': 0, '10': 0}\n",
        "    \"\"\",\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV7pqLhAQ8bp"
      },
      "source": [
        "Prompt for extarcting Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "liGHXtSNa_Yc"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are extracting entities from the text. The entities should be identified and categorized based on the given format.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following input: {question}\",\n",
        "        ),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xajy0l0b3H-T"
      },
      "source": [
        "Create a chain to show all the relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ntIUAscKbyT0"
      },
      "outputs": [],
      "source": [
        "entity_chain = prompt | llm.with_structured_output(Entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cGujozT1rP90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.query(\"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpocM7Ab5mN3"
      },
      "source": [
        "Generat the Query for the question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Tuy9F8lycaer"
      },
      "outputs": [],
      "source": [
        "def generate_full_text_query(input: str) -> str:\n",
        "    \"\"\"Generates a full-text query string for Neo4j.\n",
        "\n",
        "    Args:\n",
        "        input: The input string to generate the query from.\n",
        "\n",
        "    Returns:\n",
        "        A full-text query string.\n",
        "    \"\"\"\n",
        "    full_text_query = \"\"\n",
        "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
        "    if not words:\n",
        "        return \"\"\n",
        "    full_text_query = \" OR \".join([f\"{word}~2\" for word in words])\n",
        "\n",
        "    return full_text_query.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdwNz3oc5tXJ"
      },
      "source": [
        "Structure the Query generated to work on the Neo4j Cypher query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0OodvEf0dFfd"
      },
      "outputs": [],
      "source": [
        "def structured_retriever(question: str, max_entities = 5, max_results = 1000) -> str:\n",
        "    \"\"\"Retrieves information from the graph based on entities in the question.\n",
        "\n",
        "    Args:\n",
        "        question: The user's question.\n",
        "        max_entities: Maximum number of entities to extract (default: 5).\n",
        "        max_results: Maximum number of results to return (default: 1000).\n",
        "\n",
        "    Returns:\n",
        "        A formatted string containing the retrieved information.\n",
        "    \"\"\"\n",
        "\n",
        "    result = \"\"\n",
        "    try:\n",
        "        entities = entity_chain.invoke({\"question\": question})\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting entities: {e}\"\n",
        "\n",
        "    for entity in entities.names[:max_entities]:\n",
        "            response = graph.query(\n",
        "                \"\"\"CALL db.index.fulltext.queryNodes('entity', $query)\n",
        "                YIELD node,score\n",
        "                WITH node ORDER BY score DESC LIMIT $entity_limit\n",
        "                CALL {\n",
        "                    WITH node\n",
        "                    MATCH (node)-[r]->(neighbor)\n",
        "                    WHERE type(r) IN ['MENTIONS', 'RELATED_TO', 'DEFINES']\n",
        "                    RETURN node.id + ' -[' + type(r) + ']-> ' + neighbor.id + ': ' + coalesce(neighbor.text, '') AS output\n",
        "                    UNION ALL\n",
        "                    WITH node\n",
        "                    MATCH (node)<-[r]-(neighbor)\n",
        "                    WHERE type(r) IN ['MENTIONS', 'RELATED_TO', 'DEFINES']\n",
        "                    RETURN neighbor.id + ' -[' + type(r) + ']-> ' + node.id + ': ' + coalesce(node.text, '') AS output\n",
        "                }\n",
        "                RETURN output LIMIT $result_limit\n",
        "                \"\"\",\n",
        "                {\"query\": generate_full_text_query(entity),\n",
        "                 \"entity_limit\": 5,\n",
        "                 \"result_limit\": max_results}\n",
        "            )\n",
        "\n",
        "            if response:\n",
        "                result += \"\\n\".join([el['output'] for el in response if el['output'] is not None]) + \"\\n\"\n",
        "            else:\n",
        "                result += f\"No results found for entity: {entity}\\n\"  \n",
        "    return result.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TShf0K3bfP3_"
      },
      "outputs": [],
      "source": [
        "def retriever(question: str):\n",
        "  print(f\"\\nSearch query: {question}\\n\")\n",
        "  structured_data = structured_retriever(question)\n",
        "  unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
        "  final_data = f\"\"\"Structured data:\n",
        "  {structured_data}\n",
        "  unstructured data:\n",
        "  {\"#Document \".join(unstructured_data)}\n",
        "  \"\"\"\n",
        "  return final_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oic_-0HT4T66"
      },
      "source": [
        "Template to extract Standalone question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "_template = \"\"\"\n",
        "You are extracting entities from the text.\n",
        "Use the given format to extract information from the following input: {question}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zQZoiBk4gsw3"
      },
      "outputs": [],
      "source": [
        "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ8cU_Lx4jFj"
      },
      "source": [
        "Create a conversation from the chat history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "u8jORuZmg-vF"
      },
      "outputs": [],
      "source": [
        "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
        "  buffer = []\n",
        "  for human, ai in chat_history:\n",
        "    buffer.append(HumanMessage(content=human))\n",
        "    buffer.append(AIMessage(content=ai))\n",
        "  return buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1CKQ-Tb4r8Q"
      },
      "source": [
        "Add chat history and question to find the relationship"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EcjJtMmyhgaY"
      },
      "outputs": [],
      "source": [
        "_search_query = RunnableBranch(\n",
        "    (\n",
        "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
        "            run_name = \"HasChatHistoryCheck\"\n",
        "        ),\n",
        "        RunnablePassthrough.assign(\n",
        "            chat_history = lambda x: _format_chat_history(x[\"chat_history\"])\n",
        "        )\n",
        "        | CONDENSE_QUESTION_PROMPT\n",
        "        | ChatOpenAI(api_key = OPENAI_API_KEY)\n",
        "        | StrOutputParser()\n",
        "    ),\n",
        "    RunnableLambda(lambda x: x[\"question\"]),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-XUpXCU44z1"
      },
      "source": [
        "Prompt Template to answer in Natural language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vwcL56EajArV"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"you are a question generator, you generate questions based on following context:\n",
        "{context}\n",
        "\n",
        "the difficulty to answer the question dependes on the marks aloted to it with 1 marks being easiest and 10 being the most difficult\n",
        "\n",
        "Question: {question}\n",
        "Use natural language and be concise.\n",
        "Answer:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KwNJ2L-Pjbld"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAoO_9lY5GcD"
      },
      "source": [
        "Chain to search through the graph to get the answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Bn1Vpz3Mjk9a"
      },
      "outputs": [],
      "source": [
        "chain = (\n",
        "    RunnableParallel(\n",
        "        {\"context\": _search_query | retriever,\n",
        "        \"question\": RunnablePassthrough()}\n",
        "    )\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "logging.getLogger().setLevel(logging.CRITICAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "82q35j7xj9-s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Search query: create a question about si units for 5 marks with its answer\n",
            "\n",
            "What is the significance of SI units in standard units of measurement? \n",
            "Answer: The SI units are internationally adopted standard units of measurement that provide consistency and accuracy in scientific and everyday measurements.\n",
            "\n",
            "GoodBye\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  question = input(\"Enter your Question or 'exit' to exit: \")\n",
        "  if question.lower() == \"exit\":\n",
        "    print(\"\\nGoodBye\")\n",
        "    break\n",
        "  else:\n",
        "    print(chain.invoke({\"question\": question}))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
